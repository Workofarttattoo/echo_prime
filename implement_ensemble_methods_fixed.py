#!/usr/bin/env python3
"""
Implement Ensemble Methods & Meta-Learning
Complete the final optimization pipeline component.
"""

import sys
import os
import json
import asyncio
import time
import random

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

async def implement_ensemble_methods():
    """Implement and test ensemble methods system."""
    print("üîÄ IMPLEMENTING ENSEMBLE METHODS & META-LEARNING")
    print("=" * 55)
    
    start_time = time.time()
    
    # Test ensemble reasoner
    print("üß† Testing Ensemble Reasoner...")
    from ensemble_methods import get_ensemble_reasoner
    reasoner = get_ensemble_reasoner()
    
    test_questions = [
        {
            "question": "What are the key elements of a valid contract under UCC Article 2?",
            "domain": "legal"
        },
        {
            "question": "Solve for x: 2x + 3 = 7",
            "domain": "mathematical"
        },
        {
            "question": "Explain the difference between bad faith and negligence in insurance claims",
            "domain": "legal"
        }
    ]
    
    ensemble_results = []
    for i, test_case in enumerate(test_questions, 1):
        print(f"  Testing question {i}: {test_case['question'][:50]}...")
        
        try:
            result = await reasoner.ensemble_reason(
                test_case['question'], 
                test_case['domain'],
                max_ensemble_size=3
            )
            
            print(".2f")
            ensemble_results.append(result)
            
        except Exception as e:
            print(f"    ‚ùå Failed: {e}")
    
    # Test meta-learning adapter
    print("\nüéØ Testing Meta-Learning Adapter...")
    from ensemble_methods import get_meta_learning_adapter
    adapter = get_meta_learning_adapter()
    
    for question_data in test_questions:
        adaptation = adapter.adapt_for_task(question_data['question'], question_data['domain'])
        print(f"  {question_data['domain']}: {adaptation['task_pattern']} pattern, ensemble size {adaptation['ensemble_size']}")
        
        # Simulate recording result
        adapter.record_adaptation_result(
            question_data['domain'], 
            adaptation, 
            performance=random.uniform(0.7, 0.9),
            success=True
        )
    
    # Test active learning system
    print("\nüéì Testing Active Learning System...")
    from active_learning import get_active_learning_system
    active_learner = get_active_learning_system()
    
    # Create mock recent questions data
    recent_questions = [
        {"question": "What constitutes unreasonable delay in insurance bad faith claims?", "domain": "legal", "confidence": 0.65},
        {"question": "Solve the quadratic equation: x¬≤ + 5x + 6 = 0", "domain": "mathematical", "confidence": 0.85},
        {"question": "Explain the perfect tender rule under UCC Article 2", "domain": "legal", "confidence": 0.58},
        {"question": "What are the elements of a negligence claim?", "domain": "legal", "confidence": 0.72}
    ]
    
    focus_examples = active_learner.select_focus_examples(recent_questions, max_examples=5)
    print(f"  Identified {len(focus_examples)} focus examples for additional training")
    
    for example in focus_examples[:3]:
        analysis = example['difficulty_analysis']
        print(".2f")
    
    # Generate training data from difficult examples
    training_data = active_learner.generate_focus_training_data(focus_examples[:2])
    print(f"  Generated {len(training_data)} targeted training examples")
    
    # Test curriculum learning manager
    print("\nüìö Testing Curriculum Learning Manager...")
    from active_learning import get_curriculum_learning_manager
    curriculum = get_curriculum_learning_manager()
    
    # Mock performance data
    mock_performance = [0.75, 0.78, 0.82, 0.79, 0.81]
    current_stage = curriculum.assess_learning_stage(mock_performance)
    print(f"  Current learning stage: {current_stage}")
    
    recommendations = curriculum.get_curriculum_recommendations(current_stage, ["legal", "mathematical"])
    print(f"  Recommended ensemble size: {recommendations['ensemble_size']}")
    print(f"  Focus areas: {recommendations['focus_areas']}")
    
    # Save ensemble configuration
    ensemble_config = {
        "ensemble_reasoner": {
            "strategies_loaded": len(reasoner.strategies),
            "performance_history_domains": len(reasoner.performance_history),
            "confidence_threshold": reasoner.confidence_threshold
        },
        "meta_learning": {
            "task_patterns": len(adapter.task_patterns),
            "adaptation_history_domains": len(adapter.adaptation_history)
        },
        "active_learning": {
            "difficulty_domains": len(active_learner.difficulty_metrics),
            "learning_priorities": len(active_learner.learning_priorities)
        },
        "curriculum_learning": {
            "current_stage": current_stage,
            "learning_stages": len(curriculum.learning_stages)
        },
        "test_results": {
            "questions_tested": len(test_questions),
            "ensemble_results": len(ensemble_results),
            "focus_examples": len(focus_examples)
        },
        "timestamp": time.time()
    }
    
    os.makedirs("optimization_state", exist_ok=True)
    with open("optimization_state/ensemble_methods_config.json", 'w') as f:
        json.dump(ensemble_config, f, indent=2)
    
    elapsed = time.time() - start_time
    
    print("\nüìä ENSEMBLE METHODS IMPLEMENTATION COMPLETE")
    print(".2f")
    print(f"  üß† Ensemble reasoner: {len(reasoner.strategies)} strategies loaded")
    print(f"  üéØ Meta-learning: {len(adapter.task_patterns)} task patterns")
    print(f"  üéì Active learning: {len(active_learner.difficulty_metrics)} domains tracked")
    print(f"  üìö Curriculum: {len(curriculum.learning_stages)} learning stages")
    print("  üíæ Configuration saved to optimization_state/ensemble_methods_config.json")
    return True

async def demonstrate_ensemble_capabilities():
    """Demonstrate ensemble reasoning capabilities."""
    print("\nüé≠ DEMONSTRATING ENSEMBLE CAPABILITIES")
    print("-" * 45)
    
    from ensemble_methods import get_ensemble_reasoner
    
    reasoner = get_ensemble_reasoner()
    
    # Test complex legal question requiring ensemble reasoning
    legal_question = "Under UCC Article 2, if a seller delivers goods that don't conform to the contract specifications, what remedies are available to the buyer, and how does the perfect tender rule interact with the cure provisions?"
    
    print(f"Testing complex legal question: {legal_question[:80]}...")
    
    result = await reasoner.ensemble_reason(legal_question, "legal", max_ensemble_size=4)
    
    print("\nüéØ Ensemble Result:")
    print(f"  Final Answer: {result.final_answer[:100]}...")
    print(".2f")
    print(f"  Method Used: {result.method_used}")
    print(".2f")
    print(f"  Strategies Used: {len(result.metadata.get('strategies_used', []))}")
    print(f"  Reasoning Steps: {len(result.reasoning_steps)}")
    print(f"  Alternative Answers: {len(result.alternative_answers)}")
    
    if result.confidence_score > 0.7 and result.consensus_level > 0.5:
        print("  ‚úÖ High-confidence ensemble result achieved!")
    else:
        print("  ‚ö†Ô∏è  Ensemble result needs further refinement")

def main():
    """Main implementation function."""
    async def run():
        success = await implement_ensemble_methods()
        if success:
            await demonstrate_ensemble_capabilities()
        return success
    
    # Run async implementation
    import asyncio
    success = asyncio.run(run())
    
    if success:
        print("\nüéâ ENSEMBLE METHODS & META-LEARNING SUCCESSFULLY IMPLEMENTED!")
        print("   ECH0-PRIME now has advanced ensemble reasoning capabilities.")
        
        # Update TODO status
        from persistent_optimizations import get_persistent_optimization_manager
        pom = get_persistent_optimization_manager()
        
        # Add ensemble methods to domain strategies
        ensemble_strategies = {
            'ensemble_reasoning': {
                'prompt_template': 'Apply ensemble reasoning to: {question}',
                'reasoning_depth': 4,
                'temperature': 0.2
            },
            'meta_analysis': {
                'prompt_template': 'Perform meta-analysis of: {question}',
                'reasoning_depth': 4,
                'temperature': 0.15
            }
        }
        
        current_strategies = pom.domain_state or {}
        current_strategies.update(ensemble_strategies)
        pom.save_domain_state(current_strategies)
        
        print("   ‚úÖ Ensemble strategies added to optimization system")
        
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
