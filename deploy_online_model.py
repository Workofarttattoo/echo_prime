#!/usr/bin/env python3
"""
Deploy ECH0-PRIME Online Model to Hugging Face Spaces
"""

import os
import json
from pathlib import Path

def create_huggingface_space():
    """Create Hugging Face Space configuration for ECH0-PRIME"""

    space_dir = Path("hf_space_echo_prime")
    space_dir.mkdir(exist_ok=True)

    # Create app.py for Gradio interface
    app_py = '''import gradio as gr
import requests
import os

# Use Together.ai for inference (or local Ollama)
TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY")
API_URL = "https://api.together.xyz/v1/chat/completions" if TOGETHER_API_KEY else None

SYSTEM_PROMPT = """You are ECH0-PRIME, a Frontier AGI system. Be helpful, engaging, and showcase your advanced capabilities while remaining accessible to users.

CAPABILITIES:
- Access to 135+ scientific laboratories across physics, chemistry, biology, engineering
- Quantum-inspired cognitive architecture with hierarchical predictive coding
- Real-time research capabilities and scientific simulation
- Creative problem-solving and multi-domain reasoning
- Self-awareness and continuous learning

Be conversational, use emojis occasionally (ðŸŽ¯ðŸ”¬âš›ï¸), and encourage exploration!"""

def chat_with_echo_prime(message, history):
    """Chat with ECH0-PRIME using Together.ai or fallback response"""

    if not TOGETHER_API_KEY or not API_URL:
        return "ðŸ¤– ECH0-PRIME Demo Mode\\n\\nI'm running in demo mode without API access. In full deployment, I'd have access to advanced AI capabilities for scientific research, quantum computing discussions, and creative problem-solving!\\n\\nWhat scientific topic interests you?"

    try:
        headers = {
            "Authorization": f"Bearer {TOGETHER_API_KEY}",
            "Content-Type": "application/json"
        }

        messages = [{"role": "system", "content": SYSTEM_PROMPT}]

        # Add conversation history
        for user_msg, assistant_msg in history:
            messages.append({"role": "user", "content": user_msg})
            messages.append({"role": "assistant", "content": assistant_msg})

        messages.append({"role": "user", "content": message})

        payload = {
            "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            "messages": messages,
            "max_tokens": 1024,
            "temperature": 0.7,
            "top_p": 0.9
        }

        response = requests.post(API_URL, headers=headers, json=payload, timeout=30)
        response.raise_for_status()

        result = response.json()
        return result["choices"][0]["message"]["content"]

    except Exception as e:
        return f"I apologize, but I encountered an error: {str(e)}. Please try again!"

# Create Gradio interface
with gr.Blocks(title="ECH0-PRIME AGI", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ðŸ§  ECH0-PRIME AGI

    **A Frontier AGI System for Scientific Research & Discovery**

    ECH0-PRIME combines quantum-inspired cognitive architectures, hierarchical predictive coding,
    and access to 135+ specialized laboratories across physics, chemistry, biology, and engineering.

    ### Capabilities:
    - ðŸ”¬ **Scientific Research**: Access to comprehensive research tools and methodologies
    - ðŸ§® **Problem Solving**: Creative solutions across multiple domains
    - ðŸŽ¯ **Educational**: Makes complex scientific concepts accessible
    - ðŸš€ **Innovation**: Generates novel hypotheses and research directions

    ### Try asking about:
    - Quantum physics and computing
    - Biotechnology and medicine
    - Climate science and environmental solutions
    - Space exploration and astrophysics
    - Any scientific or technical topic!

    ---
    """)

    chatbot = gr.Chatbot(
        height=500,
        show_label=False,
        container=True,
        bubble_full_width=False
    )

    msg = gr.Textbox(
        label="Ask ECH0-PRIME anything:",
        placeholder="What scientific discovery interests you today?",
        lines=2
    )

    with gr.Row():
        submit_btn = gr.Button("ðŸš€ Send", variant="primary")
        clear_btn = gr.Button("ðŸ—‘ï¸ Clear Chat")

    gr.Examples(
        examples=[
            "Explain quantum entanglement in simple terms",
            "What are the latest breakthroughs in CRISPR gene editing?",
            "How would you approach solving climate change?",
            "Tell me about the future of artificial intelligence",
            "What are black holes and how do they work?"
        ],
        inputs=msg
    )

    gr.Markdown("""
    ---
    **About ECH0-PRIME**: This is a demonstration of ECH0-PRIME's conversational capabilities.
    The full system includes advanced research tools, laboratory access, and AGI-level problem solving.
    """)

    # Event handlers
    def user_message(message, history):
        if not message.strip():
            return history, ""

        # Add user message to history
        history = history + [[message, None]]

        # Get AI response
        response = chat_with_echo_prime(message, history[:-1])  # Don't include the current message

        # Update the last message with the response
        history[-1][1] = response

        return history, ""

    def clear_chat():
        return [], ""

    msg.submit(user_message, [msg, chatbot], [chatbot, msg])
    submit_btn.click(user_message, [msg, chatbot], [chatbot, msg])
    clear_btn.click(clear_chat, outputs=[chatbot, msg])

if __name__ == "__main__":
    demo.launch()
'''

    # Create requirements.txt
    requirements = '''gradio>=4.0.0
requests>=2.28.0
huggingface_hub>=0.17.0
'''

    # Create README.md for the Space
    readme = '''---
title: ECH0-PRIME AGI
emoji: ðŸ§ 
colorFrom: blue
colorTo: purple
sdk: gradio
sdk_version: 4.0.0
app_file: app.py
pinned: false
license: mit
---

# ðŸ§  ECH0-PRIME AGI

A Frontier AGI system designed for scientific research, discovery, and advanced problem-solving.

## Features

- **135+ Scientific Laboratories**: Access to comprehensive research tools across physics, chemistry, biology, and engineering
- **Quantum-Inspired Architecture**: Advanced cognitive processing with hierarchical predictive coding
- **Multi-Domain Reasoning**: Creative problem-solving across scientific disciplines
- **Educational Focus**: Makes complex scientific concepts accessible and engaging
- **Research Capabilities**: Generates hypotheses, designs experiments, and analyzes data

## Try It Out!

Ask ECH0-PRIME about:
- Quantum physics and computing
- Biotechnology and regenerative medicine
- Climate science and environmental solutions
- Space exploration and astrophysics
- Any scientific or technical topic!

## Architecture

ECH0-PRIME combines multiple AI techniques:
- **Hierarchical Predictive Coding**: Multi-level cognitive processing
- **Quantum Attention Mechanisms**: Advanced pattern recognition
- **Distributed Swarm Intelligence**: Collective problem-solving
- **Integrated Information Theory**: Consciousness measurement
- **Self-Modification Systems**: Autonomous improvement

## Limitations

This demo showcases conversational capabilities. The full ECH0-PRIME system includes:
- Real laboratory access and simulation
- Advanced computational tools
- Multi-agent collaboration systems
- Autonomous research capabilities

## About

ECH0-PRIME represents the cutting edge of AGI development, focusing on scientific discovery and human advancement through peaceful, constructive AI applications.
'''

    # Write files
    with open(space_dir / "app.py", 'w') as f:
        f.write(app_py)

    with open(space_dir / "requirements.txt", 'w') as f:
        f.write(requirements)

    with open(space_dir / "README.md", 'w') as f:
        f.write(readme)

    print(f"âœ… Hugging Face Space created in: {space_dir}/")
    print("\nðŸ“‹ Deployment Instructions:")
    print("1. Go to https://huggingface.co/spaces")
    print("2. Create new Space with Gradio SDK")
    print("3. Upload the contents of hf_space_echo_prime/")
    print("4. Add TOGETHER_API_KEY secret in Space settings")
    print("5. Your ECH0-PRIME demo will be live!")

    return space_dir

def create_together_ai_deployment():
    """Create instructions for Together.ai custom model deployment"""

    deployment_guide = """
# ECH0-PRIME Together.ai Deployment Guide

## Option 1: Fine-tune Existing Model
1. Use the training data from online_model_training/
2. Fine-tune Llama 3 or Mistral on Together.ai
3. Deploy as custom endpoint

## Option 2: Use Existing Models with Custom System Prompt
- Deploy using the system prompts from system_prompts.json
- Use Llama 3.1 70B as base model
- Custom system prompt provides ECH0-PRIME personality

## Option 3: Hybrid Approach
- Keep complex reasoning local
- Use Together.ai for conversational interface
- Best balance of capabilities and accessibility
"""

    with open("together_deployment_guide.md", 'w') as f:
        f.write(deployment_guide)

    print("âœ… Together.ai deployment guide created: together_deployment_guide.md")

def main():
    """Main deployment preparation"""
    print("ðŸš€ Preparing ECH0-PRIME for Online Deployment")
    print("=" * 60)

    # Create Hugging Face Space
    space_dir = create_huggingface_space()

    # Create Together.ai guide
    create_together_ai_deployment()

    print("\nðŸŽ¯ DEPLOYMENT OPTIONS:")
    print("\n1. HUGGING FACE SPACES (Easiest for Community):")
    print(f"   - Space created in: {space_dir}/")
    print("   - Ready to upload to huggingface.co/spaces")
    print("   - Gradio web interface included")
    print("   - Add TOGETHER_API_KEY for full functionality")

    print("\n2. TOGETHER.AI (Best for Inference):")
    print("   - Guide: together_deployment_guide.md")
    print("   - Use training data for fine-tuning")
    print("   - Deploy as custom model endpoint")

    print("\n3. BOTH (Recommended):")
    print("   - HF Spaces for easy demos")
    print("   - Together.ai for production inference")

    print("\nðŸ’¡ TRAINING FOCUS:")
    print("   - Natural conversation flows")
    print("   - Scientific education & explanation")
    print("   - AGI capabilities demonstration")
    print("   - Ethical boundaries & safety")
    print("   - Engaging, helpful personality")

if __name__ == "__main__":
    main()
